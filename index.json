[{"content":"现象 开发了一个下载文件的接口，使用 Content-Disposition 指定默认下载附件文件名，但是每次下载默认文件名与指定的不一致\n基础环境 JDK 8 SpringBoot 2.2.5 接口代码 出于某些原因，这里只展示下载相关的代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 import io.swagger.annotations.ApiOperation; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.core.io.FileSystemResource; import org.springframework.http.CacheControl; import org.springframework.http.MediaType; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import java.io.File; import java.net.URLEncoder; import java.util.concurrent.TimeUnit; @RestController @RequestMapping({\u0026#34;/api/v1\u0026#34;}) public class DownloadController { private Logger logger = LoggerFactory.getLogger(getClass()); @GetMapping(\u0026#34;/download/{id}\u0026#34;) @ApiOperation(\u0026#34;Download file by id\u0026#34;) public ResponseEntity\u0026lt;FileSystemResource\u0026gt; downloadFile(@PathVariable(\u0026#34;id\u0026#34;) Long id) throws Exception { String url = String.format(\u0026#34;data/%s.pdf\u0026#34;, id); File file = new File(url); if (!file.isFile()) { logger.error(\u0026#34;ERROR download file, can not find the file, ID: {}, url: {}\u0026#34;, id, url); return ResponseEntity.notFound().build(); } return ResponseEntity .ok() .header(\u0026#34;Content-Disposition\u0026#34;, \u0026#34;attachment; filename=\u0026#34; + URLEncoder.encode(file.getName(), \u0026#34;utf-8\u0026#34;)) .contentType(MediaType.APPLICATION_OCTET_STREAM) .contentLength(file.length()) .cacheControl(CacheControl.maxAge(60, TimeUnit.SECONDS)) .body(new FileSystemResource(file)); } } 具体现象 在点击下载的过程中，如果下载的文件ID为 1 时，默认下载的文件名则为 1, 而非Response header 中设置的filename 1.pdf\n原因排查 确定排查范围 接口已经经过测试，除默认设置的文件名不生效外，暂未发现其他问题。而默认设置的文件名由 .header(\u0026quot;Content-Disposition\u0026quot;, \u0026quot;attachment; filename=\u0026quot; + URLEncoder.encode(file.getName(), \u0026quot;utf-8\u0026quot;)) 这一行控制，则将范围设置为 Response header Content-Disposition 相关的问题\n查询相关信息 在确定了排查范围之后，根据相关的关键词查询信息。\n根据关键词 http response attachment filename 搜索相关的信息，在MDN Web Docs上找到了对于Content-Disposition的描述 MDN Web Docs中描述的格式如下 Content-Disposition: attachment; filename=\u0026quot;filename.jpg\u0026quot; 将接口返回的结果 Content-Disposition: attachment; filename=filename.pdf 与文档描述进行对比，发现 filename= 后面缺失了 \u0026quot; 符号。 修改相关的代码，添加 \u0026quot; 符号，将相关的代码修改如下后进行测试 1 2 3 4 5 6 7 return ResponseEntity .ok() .header(\u0026#34;Content-Disposition\u0026#34;, \u0026#34;attachment; filename=\\\u0026#34;\u0026#34; + URLEncoder.encode(file.getName(), \u0026#34;utf-8\u0026#34;) + \u0026#34;\\\u0026#34;\u0026#34;) .contentType(MediaType.APPLICATION_OCTET_STREAM) .contentLength(file.length()) .cacheControl(CacheControl.maxAge(60, TimeUnit.SECONDS)) .body(new FileSystemResource(file)); 解决方案 修改代码，在 filename= 后面添加 \u0026quot;\n","permalink":"https://puffinjiang.github.io/posts/tech/downloadattachmentfilenameinvalid/","summary":"解决文件下载中附件设置filename不生效问题","title":"Download Attachment Filename Invalid"},{"content":"挂载步骤 将硬盘插入到电脑上\n查看新磁盘是否存在 1 fdisk -l 根据显示结果查找对应的硬盘，这里是 /dev/sde1：\n1 2 3 4 5 6 7 8 9 10 Disk /dev/sde: 1.9 TiB, 2048408248320 bytes, 4000797360 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0x636b9949 Device Boot Start End Sectors Size Id Type /dev/sde1 2048 4000794623 4000792576 1.9T 7 HPFS/NTFS/exFAT 挂载硬盘 这里我将硬盘挂载到 /prod/backup 路径下，并授权读写(-rw)\n1 mount -o rw /dev/sde1 /prod/backup 查看磁盘情况 1 df -lh 使用 df -lh 命令查看磁盘是否成功挂载，如下有显示 /dev/sde 则表示正常\n1 2 tmpfs 9.5G 0 9.5G 0% /run/user/0 /dev/sde1 1.9T 951G 957G 50% /prod/backup 卸载挂载点 1 umount /dev/sde1 ","permalink":"https://puffinjiang.github.io/posts/tech/mountingaharddriveinubuntu/","summary":"在Ubuntu下挂载新硬盘","title":"Mounting A Hard Drive In Ubuntu"},{"content":"背景\u0026amp;现象 环境 操作系统：MacOS 工具：Idea、Maven\n现象 Java下的常规父子工程项目，project1依赖 project2。\n对project2单独使用mvn install时，成功 install 对project1单独使用mvn package时 报错如下： 1 Failed to execute goal on project/Could not resolve dependencies for project 原因 解决办法 步骤如下：\n使用父工程的pom文件，使用mvn clean清空相关文件 使用mvn install命令，将相关的jar安装到本地的maven仓库 对具体的project1 使用mvn package命令打包 ","permalink":"https://puffinjiang.github.io/posts/tool/mavenfailtoexecutegoalonproject/","summary":"在父子工程项目中、有依赖关系的子项目打包时找不到依赖","title":"Maven父子工程，子项目相互依赖，打包时找不到依赖"},{"content":"安装virtualbox ❗注意，一定要设置拓展包特性，后续才能使用windows远程桌面连接。Ubuntu默认是VNC的连接方式，通过设置拓展包特性，修改为vrdp的连接方式\n安装virtualbox软件 1 apt-get install virtualbox 安装拓展包 1 apt install virtualbox-ext-pack 检查拓展包是否安装成功：\n1 VBoxManage list extpacks 设置拓展包特性，为后续的远程桌面连接做准备\n1 VBoxManage setproperty vrdeextpack \u0026#34;Oracle VM VirtualBox Extension Pack\u0026#34; 创建虚拟机，并安装操作系统 创建一个虚拟机，名称为：guest_os_1，操作系统为windows10\n创建虚拟机使用的虚拟硬盘，文件路径为 /prod/vmos/guest_os_1/guest_os_1.vdi，大小为100G，即102400m\n1 VBoxManage createmedium --filename /prod/vmos/guest_os_1/guest_os_1.vdi --size 102400 创建虚拟机，名称为：guest_os_1，操作系统为：Windows10_64\n1 VBoxManage createvm --name \u0026#34;guest_os_1\u0026#34; --ostype Windows10_64 --register 如果需要安装其他类型的操作系统，可以通过如下命令查看：\n1 VBoxManage list ostypes 创建stat磁盘控制器，并和步骤一中的虚拟硬盘绑定\n1 VBoxManage storagectl guest_os_1 --name \u0026#34;SATA Controller\u0026#34; --add sata --controller IntelAHCI 绑定步骤一中的虚拟硬盘\n1 VBoxManage storageattach guest_os_1 --storagectl \u0026#34;SATA Controller\u0026#34; --port 0 --device 0 --type hdd --medium /prod/vmos/guest_os_1/guest_os_1.vdi 创建IDE控制器，设置为DVD，并和下载好的Windows10 ISO文件绑定\n1 VBoxManage storagectl guest_os_1 --name \u0026#34;IDE Controller\u0026#34; --add ide 绑定windows iso镜像文件，镜像文件路径为：/prod/iso/zh-cn_windows_10_business_editions_version_22h2_updated_nov_2022_x64_dvd_e310fb02.iso\n1 VBoxManage storageattach guest_os_1 --storagectl \u0026#34;IDE Controller\u0026#34; --port 1 --device 0 --type dvddrive --medium \u0026#34;/prod/iso/zh-cn_windows_10_business_editions_version_22h2_updated_nov_2022_x64_dvd_e310fb02.iso\u0026#34; 给虚拟机分配cpu和内存，以分配4个cpu和4g内存为例：\n1 VBoxManage modifyvm guest_os_1 --cpus 4 --memory 4096 设置虚拟机的启动顺序，首先是硬盘，其次是dvd\n1 VBoxManage modifyvm guest_os_1 --boot1 disk --boot2 dvd 打开和关闭VRDE远程连接功能，默认端口为3389\n开启VRDE远程连接：\n1 VBoxManage modifyvm guest_os_1 --vrde on 关闭VRDE远程连接：\n1 VBoxManage modifyvm guest_os_1 --vrde off 设置为自定义端口，以设置为2233为例：\n1 VBoxManage modifyvm guest_os_1 --vrdeport 2233 # 默认端口为3389 开启虚拟机\n1 VBoxManage startvm guest_os_1 --type=headless 查看虚拟机\n1 2 3 4 5 # 查看所有的虚拟机 VBoxManage list vms # 查看运行中的虚拟机 VBoxManage list runningvms 通过windows远程桌面连接虚拟机，并开始安装windows系统。以宿主机Ubuntu的ip是 192.168.0.66 为例，远程桌面连接的ip和端口应设置为 192.168.0.66:2233 ，此处的端口与步骤7 中设置的 vrdeport 保持一致。\n挂载和安装 VBoxGuestAdditions.iso 镜像\n挂载镜像：\n1 VBoxManage storageattach guest_os_1 --storagectl \u0026#34;IDE Controller\u0026#34; --port 1 --device 0 --type dvddrive --medium \u0026#34;/usr/share/virtualbox/VBoxGuestAdditions.iso\u0026#34; 开启虚拟机，进入驱动器文件下，点击对应的安装文件\nwindows安装文件路径：\n1 D:\\VBoxWindowsAdditions.exe 挂载和删除宿主机的文件夹到虚拟机\n❗注意，此挂载命令在6.1版本才生效\n挂载宿主机文件夹 \u0026lsquo;/prod/data\u0026rsquo; 为虚拟机Windows系统的 \u0026lsquo;Y:/\u0026rsquo;，相关参数作用如下：\n\u0026ndash;name 挂载的文件夹名称 \u0026ndash;hostpath 指定宿主机文件夹 \u0026ndash;readonly 设置虚拟机系统只能读数据，不允许写 1 VBoxManage sharedfolder add guest_os_1 --name \u0026#39;data\u0026#39; --hostpath \u0026#39;/prod/data\u0026#39; --readonly --automount --auto-mount-point \u0026#39;Y:/\u0026#39; 删除挂载\n1 VBoxManage sharedfolder remove guest_os_1 --name \u0026#39;data\u0026#39; 删除虚拟机 关闭虚拟机\n1 VBoxManage controlvm guest_os_1 poweroff 删除虚拟机，命令如下、此命令会删除对应虚拟机的文件及配置信息。\n1 VBoxManage unregistervm --delete guest_os_1 ","permalink":"https://puffinjiang.github.io/posts/tool/installwindowsoswithvirtualboxheadlessunderubuntu/","summary":"Ubuntu下使用无Gui的Virtualbox虚拟机安装Windows操作系统","title":"Ubuntu 下使用 Virtualbox Headless 安装 Windows 系统"},{"content":"记录一些工作过程中经常会使用的Mysql命令\nDDL（Database Definition Language） Create Database\n1 CREATE DATABASE dbname; Show Database\n1 SHOW DATABASES; Use database\n1 USE dbname; Drop Database\n1 DROP DATABASE dbname; Create Table\n1 2 3 4 5 6 7 8 CREATE TABLE IF NOT EXISTS `demo`( `id` INT UNSIGNED AUTO_INCREMENT, `name` VARCHAR(100) NOT NULL, `password` VARCHAR(40) NOT NULL, `create_time` TIMESTAMP NOT NULL DEFAULT NOW(), `update_time` TIMESTAMP NOT NUll DEFAULT CURRENT_TIMESTAMP(), PRIMARY KEY ( `runoob_id` ) )ENGINE=InnoDB DEFAULT CHARSET=utf8; Change Table\nChange name of column password to passwd\n1 ALTER TABLE demo CHANGE password passwd; Drop Table\n1 DROP TABLE demo; DML add data into table demo\n1 INSERT INTO demo(name,password) VALUES(\u0026#39;name1\u0026#39;,\u0026#39;password1\u0026#39;); Change data\n1 UPDATE demo SET name=\u0026#39;name2\u0026#39; where id = 1; delete data\n1 DELETE FROM demo WHERE id = 1; select data\nselect data by time, accurate to the second\n1 SELECT * FROM demo WHERE timestamp(create_date) BETWEEN \u0026#39;2023-01-01 00:00:00\u0026#39; AND \u0026#39;2023-01-31 00:00:00\u0026#39;; select data by date, accurate to the day\n1 SELECT * FROM demo WHERE date(create_date) BETWEEN \u0026#39;2023-01-01\u0026#39; AND \u0026#39;2023-01-31\u0026#39;; use case when to conversion some select column\n1 SELECT CASE gender WHEN 0 THEN \u0026#39;男\u0026#39; WHEN 1 THEN \u0026#39;女\u0026#39; END AS \u0026#39;性别\u0026#39;, CASE WHEN status IS NULL THEN \u0026#39;未提交\u0026#39; END AS \u0026#39;提交状态\u0026#39; FROM demo; DCL Authorization to users\n1 2 GRANT all privileges on dbname.* to username@\u0026#39;%\u0026#39; identified by password; flush privileges; Others backup backup database with mysqldump\n1 mysqldump -u root -h host -p dbname \u0026gt; backup_file.sql; restore restore database with mysqldump\n1 mysqldump -u root -h host -m dbname \u0026lt; backup_file.sql; ","permalink":"https://puffinjiang.github.io/posts/tool/mysqlcommoncommands/","summary":"记录一些常用的Mysql数据库命令","title":"Mysql Common Commands"},{"content":"记录一下开启Ubuntu服务器的ssh远程连接过程\nSSH服务安装 1. 检查服务是否开启 通过下面命令检查服务是否开启\n1 ps -e | grep sshd 2. 安装服务 1 apt install openssh-server 3. 启用服务 1 systemctl enable ssh 4. 启动服务 1 systemctl start sshd.service 服务配置 配置文件路径 注意： 使用的是sshd而不是ssh，ssh是ssh-client相关的，sshd是ssh-server相关信息，要注意区分！\n1 vim /etc/ssh/sshd_config 配置文件内容及作用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 # Package generated configuration file # See the sshd_config(5) manpage for details # What ports, IPs and protocols we listen for Port 22 # Use these options to restrict which interfaces/protocols sshd will bind to #ListenAddress :: #ListenAddress 0.0.0.0 Protocol 2 # HostKeys for protocol version 2 HostKey /etc/ssh/ssh_host_rsa_key HostKey /etc/ssh/ssh_host_dsa_key HostKey /etc/ssh/ssh_host_ecdsa_key HostKey /etc/ssh/ssh_host_ed25519_key #Privilege Separation is turned on for security UsePrivilegeSeparation yes # Lifetime and size of ephemeral version 1 server key KeyRegenerationInterval 3600 ServerKeyBits 1024 # Logging SyslogFacility AUTH LogLevel INFO # Authentication: LoginGraceTime 120 #PermitRootLogin prohibit-password PermitRootLogin yes # 允许root账号使用ssh登录 StrictModes yes RSAAuthentication yes PubkeyAuthentication yes #AuthorizedKeysFile %h/.ssh/authorized_keys # Don\u0026#39;t read the user\u0026#39;s ~/.rhosts and ~/.shosts files IgnoreRhosts yes # For this to work you will also need host keys in /etc/ssh_k nown_hosts RhostsRSAAuthentication no # similar for protocol version 2 HostbasedAuthentication no # Uncomment if you don\u0026#39;t trust ~/.ssh/known_hosts for RhostsRSAAuthentication #IgnoreUserKnownHosts yes # To enable empty passwords, change to yes (NOT RECOMMENDED) PermitEmptyPasswords no # Change to yes to enable challenge-response passwords (beware issues with # some PAM modules and threads) ChallengeResponseAuthentication no # Change to no to disable tunnelled clear text passwords #PasswordAuthentication yes # Kerberos options #KerberosAuthentication no #KerberosGetAFSToken no #KerberosOrLocalPasswd yes #KerberosTicketCleanup yes # GSSAPI options #GSSAPIAuthentication no #GSSAPICleanupCredentials yes X11Forwarding yes X11DisplayOffset 10 PrintMotd no PrintLastLog yes TCPKeepAlive yes #UseLogin no #MaxStartups 10:30:60 #Banner /etc/issue.net # Allow client to pass locale environment variables AcceptEnv LANG LC_* Subsystem sftp /usr/lib/openssh/sftp-server # Set this to \u0026#39;yes\u0026#39; to enable PAM authentication, account processing, # and session processing. If this is enabled, PAM authentication will # be allowed through the ChallengeResponseAuthentication and # PasswordAuthentication. Depending on your PAM configuration, # PAM authentication via ChallengeResponseAuthentication may bypass # the setting of \u0026#34;PermitRootLogin without-password\u0026#34;. # If you just want the PAM account and session checks to run without # PAM authentication, then enable this but set PasswordAuthentication # and ChallengeResponseAuthentication to \u0026#39;no\u0026#39;. UsePAM yes ","permalink":"https://puffinjiang.github.io/posts/tool/remoteloginofubuntuserversetting/","summary":"Ubuntu 开启ssh远程连接服务","title":"Remote Login Of Ubuntu Server Setting"},{"content":"记录一下使用docker-compose部署常用的服务\nNginx 1 2 3 4 5 6 7 8 9 10 11 12 13 version: \u0026#39;3.4\u0026#39; services: nginx: image: nginx:alpine #镜像地址 container_name: nginx #容器名 restart: always ports: - \u0026#34;443:443\u0026#34; - \u0026#34;80:80\u0026#34; volumes: - ./conf/cert/:/etc/nginx/cert/ # ssl证书路径 - ./conf/conf.d/:/etc/nginx/conf.d/ # conf配置文件 - ./logs:/var/log/nginx # 日志 Mysql 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 version: \u0026#39;3.4\u0026#39; services: db: image: mysql container_name: mysql8 restart: always environment: MYSQL_ROOT_PASSWORD: password command: --default-authentication-plugin=mysql_native_password --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci --explicit_defaults_for_timestamp=true --lower_case_table_names=1 # 重要，设置mysql不区分大小写 --max_allowed_packet=128M; ports: - \u0026#34;3306:3306\u0026#34; volumes: - ./data:/var/lib/mysql # 数据文件 - ./conf:/etc/mysql/conf.d # 配置文件 gitlab 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 version: \u0026#39;3.6\u0026#39; services: gitlab: image: \u0026#34;yrzr/gitlab-ce-arm64v8:latest\u0026#34; # 此处使用的是arm64位的镜像，系统是amd架构的直接使用 gitlab/gitlab-ce 即可 container_name: \u0026#34;gitlab\u0026#34; hostname: \u0026#39;gitlab.example.cn\u0026#39; # 域名配置 restart: always environment: GITLAB_OMNIBUS_CONFIG: | external_url \u0026#39;http://gitlab.example.cn:8181\u0026#39; #要与下面ports中的端口对应 gitlab_rails[\u0026#39;gitlab_shell_ssh_port\u0026#39;] = 2222 # gitlab_rails[\u0026#39;smtp_enable\u0026#39;] = true # gitlab_rails[\u0026#39;smtp_address\u0026#39;] = \u0026#34;smtp.aliyun.com\u0026#34; # gitlab_rails[\u0026#39;smtp_port\u0026#39;] = 465 # gitlab_rails[\u0026#39;smtp_user_name\u0026#39;] = \u0026#34;example@example.com\u0026#34; #用自己的aliyun邮箱 # gitlab_rails[\u0026#39;smtp_password\u0026#39;] = \u0026#34;password\u0026#34; # gitlab_rails[\u0026#39;smtp_domain\u0026#39;] = \u0026#34;aliyun.com\u0026#34; # gitlab_rails[\u0026#39;smtp_authentication\u0026#39;] = \u0026#34;login\u0026#34; # gitlab_rails[\u0026#39;smtp_enable_starttls_auto\u0026#39;] = true # gitlab_rails[\u0026#39;smtp_tls\u0026#39;] = true # gitlab_rails[\u0026#39;gitlab_email_from\u0026#39;] = \u0026#39;admin@example.com\u0026#39; ports: - \u0026#39;8181:8181\u0026#39; - \u0026#39;443:443\u0026#39; - \u0026#39;2222:22\u0026#39; volumes: - \u0026#39;/prod/gitlab/config:/etc/gitlab\u0026#39; - \u0026#39;/prod/gitlab/logs:/var/log/gitlab\u0026#39; - \u0026#39;/prod/gitlab/data:/var/opt/gitlab\u0026#39; shm_size: \u0026#39;256m\u0026#39; nexus个人仓库 此处需要注意的是，对于映射的data，需要授予777权限，保证正常的文件夹的创建和文件的写入\n1 2 3 4 5 6 7 8 9 10 version: \u0026#39;3.4\u0026#39; services: nexus: container_name: nexus3 image: sonatype/nexus3 restart: always ports: - \u0026#39;8889:8081\u0026#39; volumes: - /prod/nexus/data:/nexus-data ","permalink":"https://puffinjiang.github.io/posts/tool/deployservicewithdockercompose/","summary":"使用docker-compose部署常用的服务","title":"Deploy Service With Docker Compose"},{"content":"额外开销 每个索引占据一定的存储空间，在进行插入，更新和删除操作时也需要对索引进行操作。所以，如果你很少对集合进行读取操作，建议不使用索引。\n内存(RAM)使用 由于索引是存储在内存(RAM)中,你应该确保该索引的大小不超过内存的限制。\n如果索引的大小大于内存的限制，MongoDB会删除一些索引，这将导致性能下降。\n查询限制 索引不能被以下的查询使用：\n正则表达式及非操作符，如 $nin, $not, 等。 算术运算符，如 $mod, 等。 $where 子句 所以，检测你的语句是否使用索引是一个好的习惯，可以用explain来查看。\n索引键限制 从2.6版本开始，如果现有的索引字段的值超过索引键的限制，MongoDB中不会创建索引。\n插入文档超过索引键限制 如果文档的索引字段值超过了索引键的限制，MongoDB不会将任何文档转换成索引的集合。与mongorestore和mongoimport工具类似。\n最大范围 集合中索引不能超过64个 索引名的长度不能超过128个字符 一个复合索引最多可以有31个字段 ","permalink":"https://puffinjiang.github.io/posts/tool/indexlimitofmongodb/","summary":"使用MongoDB时，索引相关的限制和优化","title":"Limit Of MongoDB Index"},{"content":"Utools未实时更新环境变量配置导致命令行工具使用错误 背景 今天在使用 utools工具打开 powershell 安装 scoop ，scoop 安装成功后，可以使用 scoop 相关命令，重新打开 powershell 后使用 scoop 命令无法识别。\n问题复现 打开utools\n使用utools打开powershell\n使用powershell安装scoop\n在powershell使用scoop help命令\n关闭powershell，使用utools重新打开powershell\n在powershell中使用scoop help命令\n此时出现如下的错误信息：\n1 2 3 4 5 6 7 D : 无法将“D”项识别为 cmdlet、函数、脚本文件或可运行程序的名称。请检查名称的拼写，如果包括路径，请确保路径正确，然后 再试一次。 所在位置 行:1 字符: 1 + D + ~ + CategoryInfo : ObjectNotFound: (D:String) [], CommandNotFoundException + FullyQualifiedErrorId : CommandNotFoundException 解决方法 重新启动 utools\n","permalink":"https://puffinjiang.github.io/posts/tool/utoolscannotgetnewenvfromsystem/","summary":"utools无法及时更新最新的系统环境变量，导致在使用powershell等命令行工具时无法读取相应的环境变量","title":"Utools Can not Get New Env From System"},{"content":"背景 今天在我更新完苹果推送的系统更新之后，打开vscode时，弹窗提示 Git无法使用 之类的信息。让我以为更新之后Git被删除了， 于是我使用 brew upgrade git 命令想看一下之前安装过的Git是否还在\n问题 使用 brew install git 命令时，报如下错误：\n1 2 3 4 5 6 7 8 9 10 11 Warning: You are using macOS 13. We do not provide support for this pre-release version. You will encounter build failures with some formulae. Please create pull requests instead of asking for help on Homebrew\u0026#39;s GitHub, Twitter or any other official channels. You are responsible for resolving any issues you experience while you are running this pre-release version. Error: No developer tools installed. Install the Command Line Tools: xcode-select --install 解决方法 运行 xcode-select --install ，此命令会安装会帮助我们安装 Command Line Tools，安装完成后即可正常使用 brew 命令了。\n","permalink":"https://puffinjiang.github.io/posts/tool/upgradebrewerrorafterupdatingmacos/","summary":"Git can not used after I updated the MacOS","title":"Upgrade brew error after updating MacOS"},{"content":"Flask简介 Flask是一个“微” python web 框架，只实现了最基本的功能，简单、灵活、可拓展性强。\n简单：使用简单，通过 @app.route() 装饰器即可配置路由 灵活：配置灵活，支持多种不同类型的配置方式。可自定义 使用dict对象 使用环境变量 app.config.from_envvar() 使用配置文件 app.config.from_file() 包括json、toml 可拓展性强：可自定义其他部分的组件，如 flask-SQLAlchemy、flask-session 等 依赖 flask依赖的核心组件有2个： werkzeug 和 jinja。 jinja 是一个模版引擎，负责模版的渲染，werkzeug 是一个 WSGI 工具集的库\n启动流程 在Flask的官方文档中给了一个 \u0026lsquo;Hello World\u0026rsquo; 启动案例，我们本地启动一下\n1 2 3 4 5 6 7 8 9 10 from flask import Flask app = Flask(__name__) @app.route(\u0026#34;/\u0026#34;) def hello_world(): return \u0026#34;\u0026lt;p\u0026gt;Hello, World!\u0026lt;/p\u0026gt;\u0026#34; if __name__ == \u0026#39;__main__\u0026#39;: app.run(\u0026#34;127.0.0.1\u0026#34;, 5000) 我们可以看出来，启动的时候首先调用了 app.run() 方法，我们来看一下这个方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 class Flask(Scaffold): def run( self, host: t.Optional[str] = None, port: t.Optional[int] = None, debug: t.Optional[bool] = None, load_dotenv: bool = True, **options: t.Any, ) -\u0026gt; None: # Change this into a no-op if the server is invoked from the # command line. Have a look at cli.py for more information. if os.environ.get(\u0026#34;FLASK_RUN_FROM_CLI\u0026#34;) == \u0026#34;true\u0026#34;: from .debughelpers import explain_ignored_app_run explain_ignored_app_run() return if get_load_dotenv(load_dotenv): cli.load_dotenv() # if set, let env vars override previous values if \u0026#34;FLASK_ENV\u0026#34; in os.environ: self.env = get_env() self.debug = get_debug_flag() elif \u0026#34;FLASK_DEBUG\u0026#34; in os.environ: self.debug = get_debug_flag() # debug passed to method overrides all other sources if debug is not None: self.debug = bool(debug) server_name = self.config.get(\u0026#34;SERVER_NAME\u0026#34;) sn_host = sn_port = None if server_name: sn_host, _, sn_port = server_name.partition(\u0026#34;:\u0026#34;) if not host: if sn_host: host = sn_host else: host = \u0026#34;127.0.0.1\u0026#34; if port or port == 0: port = int(port) elif sn_port: port = int(sn_port) else: port = 5000 options.setdefault(\u0026#34;use_reloader\u0026#34;, self.debug) options.setdefault(\u0026#34;use_debugger\u0026#34;, self.debug) options.setdefault(\u0026#34;threaded\u0026#34;, True) cli.show_server_banner(self.env, self.debug, self.name, False) from werkzeug.serving import run_simple try: run_simple(t.cast(str, host), port, self, **options) finally: # reset the first request information if the development server # reset normally. This makes it possible to restart the server # without reloader and that stuff from an interactive shell. self._got_first_request = False 我们可以看到，前面一部分主要是处理一些启动参数。在参数处理完成之后，调用了 werkzeug.serving 中的 run_simple 函数，能看到这个函数传入了一个 self 参数，即我们的 flask application，我们再进入这个 run_simple 当中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 # werkzeug相关代码 def run_simple( hostname: str, port: int, application: \u0026#34;WSGIApplication\u0026#34;, use_reloader: bool = False, use_debugger: bool = False, use_evalex: bool = True, extra_files: t.Optional[t.Iterable[str]] = None, exclude_patterns: t.Optional[t.Iterable[str]] = None, reloader_interval: int = 1, reloader_type: str = \u0026#34;auto\u0026#34;, threaded: bool = False, processes: int = 1, request_handler: t.Optional[t.Type[WSGIRequestHandler]] = None, static_files: t.Optional[t.Dict[str, t.Union[str, t.Tuple[str, str]]]] = None, passthrough_errors: bool = False, ssl_context: t.Optional[_TSSLContextArg] = None, ) -\u0026gt; None: if not isinstance(port, int): raise TypeError(\u0026#34;port must be an integer\u0026#34;) if static_files: from .middleware.shared_data import SharedDataMiddleware # 静态文件的加载 application = SharedDataMiddleware(application, static_files) if use_debugger: from .debug import DebuggedApplication # Debug调试 application = DebuggedApplication(application, evalex=use_evalex) if not is_running_from_reloader(): # 启动前 socket 的准备和检查 ，使用IPV4还是IPV6、端口是否占用 s = prepare_socket(hostname, port) fd = s.fileno() os.environ[\u0026#34;WERKZEUG_SERVER_FD\u0026#34;] = str(fd) else: fd = int(os.environ[\u0026#34;WERKZEUG_SERVER_FD\u0026#34;]) srv = make_server( hostname, port, application, threaded, processes, request_handler, passthrough_errors, ssl_context, fd=fd, ) if not is_running_from_reloader(): srv.log_startup() if use_reloader: from ._reloader import run_with_reloader run_with_reloader( srv.serve_forever, extra_files=extra_files, exclude_patterns=exclude_patterns, interval=reloader_interval, reloader_type=reloader_type, ) else: srv.serve_forever() 从上面的代码我们可以看到有两处关键的函数调用，一处是 make_server ，另外一处是 serve_forever 。我们先看 make_server 做了什么：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # werkzeug相关代码 def make_server( host: str, port: int, app: \u0026#34;WSGIApplication\u0026#34;, threaded: bool = False, processes: int = 1, request_handler: t.Optional[t.Type[WSGIRequestHandler]] = None, passthrough_errors: bool = False, ssl_context: t.Optional[_TSSLContextArg] = None, fd: t.Optional[int] = None, ) -\u0026gt; BaseWSGIServer: if threaded and processes \u0026gt; 1: raise ValueError(\u0026#34;Cannot have a multi-thread and multi-process server.\u0026#34;) if threaded: # ThreadedWSGIServer 继承了 BaseWSGIServer return ThreadedWSGIServer( host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd ) if processes \u0026gt; 1: # ForkingWSGIServer 继承了 BaseWSGIServer return ForkingWSGIServer( host, port, app, processes, request_handler, passthrough_errors, ssl_context, fd=fd, ) return BaseWSGIServer( host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd ) 能看到这里是返回了一个 BaseWSGIServer 实例化对象。BaseWSGIServer 在初始化的时候主要做了 两件事情，一是 绑定IP和端口以及监听；二是添加 WSGIRequestHandler 这个请求处理器。\n我们再来看看 serve_forever 做了什么：\n1 2 3 4 5 6 7 8 9 10 # werkzeug相关代码 class BaseWSGIServer(HTTPServer): def serve_forever(self, poll_interval: float = 0.5) -\u0026gt; None: try: super().serve_forever(poll_interval=poll_interval) except KeyboardInterrupt: pass finally: self.server_close() 再来进一步看看父类的 serve_forever 做了什么：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # werkzeug相关代码 class BaseServer: def serve_forever(self, poll_interval=0.5): \u0026#34;\u0026#34;\u0026#34;Handle one request at a time until shutdown. Polls for shutdown every poll_interval seconds. Ignores self.timeout. If you need to do periodic tasks, do them in another thread. \u0026#34;\u0026#34;\u0026#34; self.__is_shut_down.clear() try: # XXX: Consider using another file descriptor or connecting to the # socket to wake this up instead of polling. Polling reduces our # responsiveness to a shutdown request and wastes cpu at all other # times. # I/O多路复用选择器，有poll时选poll with _ServerSelector() as selector: selector.register(self, selectors.EVENT_READ) while not self.__shutdown_request: # 轮询 ready = selector.select(poll_interval) # bpo-35017: shutdown() called during select(), exit immediately. if self.__shutdown_request: break if ready: self._handle_request_noblock() self.service_actions() finally: self.__shutdown_request = False self.__is_shut_down.set() 我们可以看到的是直接跳到了 BaseServer 这个类，这因为 BaseWSGIServer \u0026ndash;\u0026gt; HTTPServer \u0026ndash;\u0026gt; TCPServer \u0026ndash;\u0026gt; BaseServer 他们之间有继承关系。此处选用了 PollSelector 作为 I/O多路复用选择器，关于I/O多路复用就不详说了。当有活跃的文件描述符时，执行 _handle_request_noblock()方法，到了这里，我们的应用启动并开始监听相关的端口了。\n请求处理过程 在上面我们已经说到了应用的启动过程，接下来看一看当接收到请求之后是怎么处理的。 上面说到，当有活跃的文件描述符会执行 _handle_request_noblock() 方法，来看一下这个方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # werkzeug相关代码 class BaseServer: def _handle_request_noblock(self): \u0026#34;\u0026#34;\u0026#34;Handle one request, without blocking. I assume that selector.select() has returned that the socket is readable before this function was called, so there should be no risk of blocking in get_request(). \u0026#34;\u0026#34;\u0026#34; try: request, client_address = self.get_request() except OSError: return if self.verify_request(request, client_address): try: self.process_request(request, client_address) except Exception: self.handle_error(request, client_address) self.shutdown_request(request) except: self.shutdown_request(request) raise else: self.shutdown_request(request) 在这段代码里我们可以看出来，这里是调用了 process_request 方法去处理接收到的request，这个时候就到了我们前面提到的 WSGIRequestHandler 这个请求处理器了。 WSGIRequestHandler 是 BaseRequestHandler 的子类，看看初始化相关的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # werkzeug相关代码 class BaseRequestHandler: def __init__(self, request, client_address, server): self.request = request self.client_address = client_address self.server = server self.setup() try: self.handle() finally: self.finish() def setup(self): pass def handle(self): pass def finish(self): pass 从上面的代码中可以看到，初始化时调用了 handle 方法，在 handle 方法里是调用了 handle_one_request 方法，我们来看看这个方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 # werkzeug相关代码 class BaseHTTPRequestHandler(socketserver.StreamRequestHandler): def handle_one_request(self): \u0026#34;\u0026#34;\u0026#34;Handle a single HTTP request. You normally don\u0026#39;t need to override this method; see the class __doc__ string for information on how to handle specific HTTP commands such as GET and POST. \u0026#34;\u0026#34;\u0026#34; try: self.raw_requestline = self.rfile.readline(65537) if len(self.raw_requestline) \u0026gt; 65536: self.requestline = \u0026#39;\u0026#39; self.request_version = \u0026#39;\u0026#39; self.command = \u0026#39;\u0026#39; self.send_error(HTTPStatus.REQUEST_URI_TOO_LONG) return if not self.raw_requestline: self.close_connection = True return if not self.parse_request(): # An error code has been sent, just exit return mname = \u0026#39;do_\u0026#39; + self.command if not hasattr(self, mname): self.send_error( HTTPStatus.NOT_IMPLEMENTED, \u0026#34;Unsupported method (%r)\u0026#34; % self.command) return method = getattr(self, mname) method() self.wfile.flush() #actually send the response if not already done. except socket.timeout as e: #a read or a write timed out. Discard this connection self.log_error(\u0026#34;Request timed out: %r\u0026#34;, e) self.close_connection = True return 可以看到关键的地方是这个 method 方法的调用，而这个 method 其实就是 do_GET、do_POST 等方法。通过 debug 看到，这个方法和 WSGIRequestHandler.run_wsgi 绑定了，即调用了 WSGIRequestHandler.run_wsgi 方法，这是很关键的一个方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 # werkzeug相关代码 class WSGIRequestHandler(BaseHTTPRequestHandler): def run_wsgi(self) -\u0026gt; None: if self.headers.get(\u0026#34;Expect\u0026#34;, \u0026#34;\u0026#34;).lower().strip() == \u0026#34;100-continue\u0026#34;: self.wfile.write(b\u0026#34;HTTP/1.1 100 Continue\\r\\n\\r\\n\u0026#34;) self.environ = environ = self.make_environ() status_set: t.Optional[str] = None headers_set: t.Optional[t.List[t.Tuple[str, str]]] = None status_sent: t.Optional[str] = None headers_sent: t.Optional[t.List[t.Tuple[str, str]]] = None chunk_response: bool = False def write(data: bytes) -\u0026gt; None: nonlocal status_sent, headers_sent, chunk_response assert status_set is not None, \u0026#34;write() before start_response\u0026#34; assert headers_set is not None, \u0026#34;write() before start_response\u0026#34; if status_sent is None: status_sent = status_set headers_sent = headers_set try: code_str, msg = status_sent.split(None, 1) except ValueError: code_str, msg = status_sent, \u0026#34;\u0026#34; code = int(code_str) self.send_response(code, msg) header_keys = set() for key, value in headers_sent: self.send_header(key, value) header_keys.add(key.lower()) # Use chunked transfer encoding if there is no content # length. Do not use for 1xx and 204 responses. 304 # responses and HEAD requests are also excluded, which # is the more conservative behavior and matches other # parts of the code. # https://httpwg.org/specs/rfc7230.html#rfc.section.3.3.1 if ( not ( \u0026#34;content-length\u0026#34; in header_keys or environ[\u0026#34;REQUEST_METHOD\u0026#34;] == \u0026#34;HEAD\u0026#34; or (100 \u0026lt;= code \u0026lt; 200) or code in {204, 304} ) and self.protocol_version \u0026gt;= \u0026#34;HTTP/1.1\u0026#34; ): chunk_response = True self.send_header(\u0026#34;Transfer-Encoding\u0026#34;, \u0026#34;chunked\u0026#34;) # Always close the connection. This disables HTTP/1.1 # keep-alive connections. They aren\u0026#39;t handled well by # Python\u0026#39;s http.server because it doesn\u0026#39;t know how to # drain the stream before the next request line. self.send_header(\u0026#34;Connection\u0026#34;, \u0026#34;close\u0026#34;) self.end_headers() assert isinstance(data, bytes), \u0026#34;applications must write bytes\u0026#34; if data: if chunk_response: self.wfile.write(hex(len(data))[2:].encode()) self.wfile.write(b\u0026#34;\\r\\n\u0026#34;) self.wfile.write(data) if chunk_response: self.wfile.write(b\u0026#34;\\r\\n\u0026#34;) self.wfile.flush() def start_response(status, headers, exc_info=None): # type: ignore nonlocal status_set, headers_set if exc_info: try: if headers_sent: raise exc_info[1].with_traceback(exc_info[2]) finally: exc_info = None elif headers_set: raise AssertionError(\u0026#34;Headers already set\u0026#34;) status_set = status headers_set = headers return write def execute(app: \u0026#34;WSGIApplication\u0026#34;) -\u0026gt; None: application_iter = app(environ, start_response) try: for data in application_iter: write(data) if not headers_sent: write(b\u0026#34;\u0026#34;) if chunk_response: self.wfile.write(b\u0026#34;0\\r\\n\\r\\n\u0026#34;) finally: if hasattr(application_iter, \u0026#34;close\u0026#34;): application_iter.close() # type: ignore try: execute(self.server.app) except (ConnectionError, socket.timeout) as e: self.connection_dropped(e, environ) except Exception as e: if self.server.passthrough_errors: raise if status_sent is not None and chunk_response: self.close_connection = True try: # if we haven\u0026#39;t yet sent the headers but they are set # we roll back to be able to set them again. if status_sent is None: status_set = None headers_set = None execute(InternalServerError()) except Exception: pass from .debug.tbtools import DebugTraceback msg = DebugTraceback(e).render_traceback_text() self.server.log(\u0026#34;error\u0026#34;, f\u0026#34;Error on request:\\n{msg}\u0026#34;) 这段代码里是 execute(self.server.app) 这一段，而这个 server.app 其实就是我们传进来的 flask application了，通过 application_iter = app(environ, start_response) 这一行调用了 Flask 的 __call__ 方法。上面涉及到了很多 werkzeug 相关的代码，然后在这里又回到了 flask。 来看一看这个方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # Flask相关代码 class Flask(Scaffold): def __call__(self, environ: dict, start_response: t.Callable) -\u0026gt; t.Any: \u0026#34;\u0026#34;\u0026#34;The WSGI server calls the Flask application object as the WSGI application. This calls :meth:`wsgi_app`, which can be wrapped to apply middleware. \u0026#34;\u0026#34;\u0026#34; return self.wsgi_app(environ, start_response) def wsgi_app(self, environ: dict, start_response: t.Callable) -\u0026gt; t.Any: # 创建请求的上下文 ctx = self.request_context(environ) error: t.Optional[BaseException] = None try: try: ctx.push() response = self.full_dispatch_request() except Exception as e: error = e response = self.handle_exception(e) except: # noqa: B001 error = sys.exc_info()[1] raise return response(environ, start_response) finally: if self.should_ignore_error(error): error = None ctx.auto_pop(error) 这段代码首先是创建请求的上下文，然后通过 self.full_dispatch_request() 方法分发请求，我们再来看看 full_dispatch_request 的具体代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 class Flask(Scaffold): def full_dispatch_request(self) -\u0026gt; Response: # Run before_first_request functions if this is the thread\u0026#39;s first request. # Inlined to avoid a method call on subsequent requests. # This is deprecated, will be removed in Flask 2.3. if not self._got_first_request: with self._before_request_lock: if not self._got_first_request: for func in self.before_first_request_funcs: self.ensure_sync(func)() self._got_first_request = True try: request_started.send(self) rv = self.preprocess_request() if rv is None: rv = self.dispatch_request() except Exception as e: rv = self.handle_user_exception(e) return self.finalize_request(rv) def dispatch_request(self) -\u0026gt; ft.ResponseReturnValue: req = request_ctx.request if req.routing_exception is not None: self.raise_routing_exception(req) rule: Rule = req.url_rule # type: ignore[assignment] # if we provide automatic options for this URL and the # request came with the OPTIONS method, reply automatically if ( getattr(rule, \u0026#34;provide_automatic_options\u0026#34;, False) and req.method == \u0026#34;OPTIONS\u0026#34; ): return self.make_default_options_response() # otherwise dispatch to the handler for that endpoint view_args: t.Dict[str, t.Any] = req.view_args # type: ignore[assignment] return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args) 能看的到这里 dispatch_request 分发请求，使用 handle_user_exception 处理分发过程中的异常处理。在 dispatch_request 当中，根据url路径，找到相应的方法，并调用，代码为 self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)。我们再来看一看 self.finalize_request(rv) 做了什么：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # Flask相关代码 class Flask(Scaffold): def finalize_request( self, rv: t.Union[ResponseReturnValue, HTTPException], from_error_handler: bool = False, ) -\u0026gt; Response: response = self.make_response(rv) try: response = self.process_response(response) request_finished.send(self, response=response) except Exception: if not from_error_handler: raise self.logger.exception( \u0026#34;Request finalizing failed with an error while handling an error\u0026#34; ) return response 这里的 finalize_request() 就是把 view_functions 返回的结果组装成 Response 并返回，在其中处理了 status、headers、session 等，到此我们的请求处理就结束了。\n","permalink":"https://puffinjiang.github.io/posts/tech/flask%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","summary":"记录一下阅读Flask源码的过程","title":"Flask源码阅读"},{"content":"最近在使用celery这个异步框架，在使用的过程中，发现worker运行一段时间后，内存持续上涨，然后告警 在网上查询之后发现了Celery有内存泄漏的问题，requests包也会有内存泄漏的问题 在网上查到的解决方法是\n在worker执行指定次数任务后重建新进程\n1 2 # 执行32次后被干掉 worker_max_tasks_per_child = 32 在worker内存到达指定限制后重建新进程\n1 2 # 内存使用量达到 12m 后被干掉 worker_max_memory_per_child = 12000 # 12m ","permalink":"https://puffinjiang.github.io/posts/tech/celery%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E8%A7%A3%E5%86%B3/","summary":"记一次Celery内存泄漏的问题解决","title":"Celery内存泄漏解决"},{"content":"","permalink":"https://puffinjiang.github.io/links/","summary":"","title":"🤝友链"},{"content":"连接 使用 psql 远程连接 使用uri方式 1 psql postgres://username:password@host:port/dbname 使用普通的参数方式 1 psql -U username -h hostname -p port -d dbname 查询 列出所有的数据库名 1 SELECT datname FROM pg_database; 数据库创建操作 创建用户名和密码 1 create user username with encrypted password \u0026#39;password\u0026#39;; 创建新的数据库 1 create database dbname ; 数据库授权操作 1 2 -- 将数据库 dbname 授权给用户 username grant all privileges on database dbname to username; 备份和恢复 表备份 1 CREATE TABLE new_table AS SELECT * FROM public.old_table; 表数据删除 TRUNCATE 命令（全表数据删除）\n1 TRUNCATE TABLE public.new_table; DELETE 命令\n1 DELETE FROM TABLE WHERE id = 1; ","permalink":"https://puffinjiang.github.io/posts/tool/postgresql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/","summary":"记录一些常用的PostgreSQL数据库操作命令","title":"PostgreSQL数据库常用操作"},{"content":"前置条件 windows系统、github设置隐私邮箱\n使用Github给的邮箱替换了原有的邮箱，命令如下：\n1 2 git config --global user.name \u0026#34;xxx\u0026#34; git config --global user.email \u0026#34;xxx\u0026#34; 用旧的邮箱进行了commit\n过程 在替换为新的邮箱之后使用 git push 命令提交代码被拒绝，返回以下提示：\n1 2 3 4 Can\u0026#39;t finish GitHub sharing process Successfully created project \u0026#39;xxx\u0026#39; on GitHub, but initial push failed: remote: error: GH007: Your push would publish a private email address. failed to push some refs to \u0026#39;xxx\u0026#39; 使用 git config --list 查看邮箱是否正确\n1 2 user.name=xxx user.email=xxx 发现没有问题，和修改后的邮箱一直\n经过回溯之后，发现在修改邮箱之前，使用原来的邮箱进行了 commit，但是没有 push。因此commit的内容用的还是原来的邮箱，导致push时报错\n解决方法 使用 git reset 命令回退版本到 commit 之前 重新 commit 和 push，push 成功 ","permalink":"https://puffinjiang.github.io/posts/tool/git%E6%8E%A8%E9%80%81%E4%BB%A3%E7%A0%81%E5%A4%B1%E8%B4%A5/","summary":"在使用 git push时报 remote: error: GH007: Your push would publish a private email address.","title":"Git推送代码失败"},{"content":"👨‍💻 职业 程序员\n开发语言 Python Java 数据库 Mysql PostgreSQL Redis MongoDB DevOps Jenkins Docker Docker-compose ⛹ 兴趣爱好 运动：足球、羽毛球、篮球等 阅读：技术书籍、小说等 动漫：《凡人修仙传》、《某科学的超电磁炮》等 游戏：CSGO 📬 联系我呀","permalink":"https://puffinjiang.github.io/about/","summary":"","title":"🙋🏻‍♂️关于我"}]